---
firstname: Daniel
lastname: Fitz
number: 43961229
code: deco2500
course: Human Computer Interaction Design
title: Textbook Summary
toc: toc
headrule: 0.12em
figPrefix: "Figure "
eqnPrefix: "Equation "
tblPrefix: "Table "
secPrefix: "Section "
output:
    pdf_document:
        md_extensions: +grid_tables
---

# Chapter 1 -- What is Interaction Design
- Explain the difference between good and poor interaction design
- Describe what interaction design is and how it relates to human-computer interaction and other fields
- Explain the relationship between the user experience and usability
- Describe what and who is involved in the process of interaction design
- Outline the different forms of guidance used in interaction design
- Enable you to evaluate an interactive product and explain what is good and bad about it in terms of the goals and core principles of interaction design

## What is Interaction Design
> _"designing interactive products to support the way people communicate and interact in their everyday and working lives"_

Interaction design is used in:

- Academic Disciplines
- Ergonomics
- Psychology/Cognitive Science
- Design
- Informatics
- Engineering
- Computer Science/Software Engineering
- Social Sciences (e.g. Sociology, Anthropology)
- Ubiquitous Computing
- Human Factors (HF)
- Cognitive Engineering
- Human-Computer Interaction (HCI)
- Cognitive Ergonomics
- Computer-Supported Cooperative Work (CSCW)
- Information Systems
- Film Industry
- Industrial Design
- Artist-Design
- Product Design
- Graphic Design

### The Process of Interaction Design
1. Establishing requirements
1. Designing alternatives
1. Prototyping
1. Evaluating

## The User Experience (UX)
Nielsen and Norman (2014) define it as encompassing "all aspects fo the end-user's interaction with the company, its services, and its products." You cannot design a user experience, you can only design for the user experience. There are many aspects of the user experience that can be considered and ways of taking them into account when designing interactive products.

- Usability
- Functionality
- Aesthetics
- Content
- Look and Feel
- Sensual
- Emotional
- Fun
- Health
- Social Capital
- Cultural Identity

### Four Core Threads
McCarthy and Wright propose four core threads that make up our holistic experiences:

- **The sensual thread**. This is concerned with our sensory engagement with a situation and is similar to the visceral level of Norman's model. It can be equated with the level of absorption people have with various technological devices and applications, most notable being computer games, smartphones, and chat rooms, where users can be highly absorbed in their interactions at a sensory level. These can involve thrill, fear, pain, and comfort.
- **The emotional thread**. Common examples of emotions that spring to mind are sorrow, anger, joy and happiness. In addition, the framework points out how emotions are intertwined with the situation in which they arise -- e.g. a person becomes angry with a computer because it does not work properly. Emotions also invoke making judgements of value. For example, when purchasing a new cell phone, people may be drawn to the ones that are most cool-looking but be in an emotional turmoil because they are the most expensive. They can't really afford them but they really would like one of them.
- **The compositional thread**. This is concerned with the narrative part of an experience, as it unfolds, and the way a person makes sense of it. For example, when shopping online, the options laid out to people can lead them in a coherent way to making a desired purchase or they can lead to frustrating experiences resulting in no purchase being made. When in this situation, people ask themselves questions such as: What is this about? What would happen if...? The compositional thread is the internal thinking we do during our experiences.
- **The spatio-temporal thread**. This refers to the space and time in which our experiences take place and their effect upon those experiences. There are many ways of thinking about space and time and their relationship with one another: for example, we talk of time speeding up, standing still, and slowing down, whilw we talk of space in terms of public and personal places, and needing one's own space.

## Usability Goals
- effective to use (effectiveness)
- efficient to use (efficiency)
- safe to use (safety)
- having good utility (utility)
- easy to learn (learnability)
- easy to remember how to use (memorability)

### Design Principles
Design principles are used by interaction designers to aid their thinking when designing for the user experience.

- **Feedback:** products should be designed to provide adequate feedback to the users to ensure they know what to do next in their tasks
- **Findability:** the degree to which a particular object is easy to discover or locate -- be it navigating a website, moving through a building, or finding the delete image option on digital camera
- **Visibility:** the more visible functions are, the more likely it is that users will be able to know to do next
- **Constraints:** the design concept of constraining refers to determining ways of restricting the kinds of user interaction that can take place at a given moment (e.g. greying a menu item)
- **Consistency:** design interfaces to have similar operations and use similar elements for achieving similar tasks
- **Affordance:** used to refer to an attribute of an object that allows people to know how to use it (e.g. a mouse button invites pushing, in doing so activating clicking, by the way it is physically constrained)

## Summary
### Key points
- Interaction design is concerned with designing interactive products to support the way people communicate and interact in their everyday and working lives
- Interaction design is multidisciplinary, involving many inputs from wide-ranging disciplines and fields
- The notion of the user experience is central to interaction design
- Optimizing the interaction between users and interactive products requires taking into account a number of interdependent factors, including context of use, types of activity, accessibility, cultural differences, and user groups
- Identifying and specifying relevant usability and user experience goals can help lead to the design of good interactive products
- Design principles, such as feedback and simplicity, are useful heuristics for analysing and evaluating aspects of an interactive product

## Examples
### Marble Answering Machine (Durrel Bishop, 1995)
Incoming messages are represented using physical marbles. The number of marbles that have moved into the pinball-like chute indicates the number of messages. Dropping one of these marbles into a slot in the machine causes the recorded message to play. Dropping the same marble into another slot on the phone dials the caller who left the message

### Minuum Online Keyboard
Easy way of typing using minimal buttons. Similar to Wii remotes where you point to a row of keys and type that way. This is faster to use on a small device, especially with one hand

# Chapter 2 -- Understanding and Conceptualizing Interaction
- Explain what is meant by the problem space
- Explain how to conceptualize interaction
- Describe what a conceptual model is and how to begin to formulate one
- Discuss the use of interface metaphors as part of a conceptual model
- Outline the core interaction types for informing the development of a conceptual model
- Introduce paradigms, visions, theories, models, and frameworks informing interaction design

## Understanding the Problem Space and Conceptualizing Interaction
Having a good understanding of the problem space greatly helps design teams to then be able to conceptualize the design space. Primarily this involves articulating the proposed system and the user experience. The benefits of conceptualizing the design space early on are:

- **Orientation** -- enabling the design team to ask specific kinds of questions about how the conceptual model will be understood by the targeted users
- **Open-mindedness** -- preventing the design team from becoming narrowly focused early on
- **Common ground** -- allowing the design team to establish a set of common terms that all can understand and agree upon, reducing the chance of misunderstandings and confusion arising later on

## Conceptual Models
In a nutshell, a conceptual model provides a working strategy and a framework of general concepts and their interrelations. The core components are:

- Metaphors and analogies that convey to people how to understand what a product is for and how to use it for an activity (e.g. browsing, bookmarking)
- The concepts that people are exposed to through the product, including the task -- domain objects they create and manipulate, their attributes, and the operations that can be performed on them (e.g. saving, revisiting, organizing)
- The relationships between those concepts (e.g. whether one object contains another, the relative importance of actions to others, and whether an object is part of another)
- The mappings between the concepts and the user experience the product is designed to support or invoke (e.g. one can revisit through looking at a list of visited sites, most-frequently visited, or saved websites)

### Design Concept
Design concept is essentially a set of ideas for a design. Typically is comprises of scenarios, images, mood boards, or text-based documents.

## Interface Metaphors
Metaphors are considered to be a central component of a conceptual model. They provide a structure that is similar in some way to aspects of a familiar entity (or entities) but also have their own behaviours and properties. More specifically, an interface metaphor is one that is instantiated in some way as part of the user interface.\
Metaphors and analogies are used in three main ways:

1. As a way of conceptualizing what we are doing (e.g. surfing the web)
1. As a conceptual model instantiated at the interface (e.g. the card metaphore)
1. As a way of visualizing an operation (e.g. an icon of a shopping cart into which we place items we wish to purchase on an online shopping site)

## Interaction Types
The way a user will interact with a product or application. Four main types of interaction:

- **Instructing** -- where users issue instructions to a system. This can be done in a number of ways, including: typing in commands, selecting options from menus in a windows environment or on a multitouch screen, speaking aloud commands, gesturing, pressing buttons, or using a combination of function keys
- **Conversing** -- where users have a dialog with a system. Users can speak via an interface or type in questions to which the system replies via text or speech output
- **Manipulating** -- where users interact with objects in a virtual or physical space by manipulating them (e.g. opening, holding, closing, placing). User can hone their familiar knowledge of how to interact with objects
- **Exploring** -- where users move through a virtual environment or a physical space. Vritual environments include 3D worlds, and augmented and virtual reality systems. They enable users to hone their familiar knowledge of physically moving around. Physical spaces that use sensor-based technologies include smart rooms and ambient environments, also enabling people to capitalize on familiarity

## Paradigms, Visions, Theories, Models, and Frameworks
(Carrol, 2003)

- **Paradigm** refers to a general approach that has been adopted by a community of researchers and designers for carrying out their work, in terms of shared assumptions, concepts, values, and practices
- **Vision** is a future scenario that frames research and development in interaction design -- often depicted in the form of a film or a narrative
- **Theory** is a well-substantiated explanation of some aspect of a phenomenon
- **Model** is a simplification of some aspect of human-computer interaction intended to make it easier for designers to predict and evaluate alternative designs
- **Framework** is a set of interrelated concepts and/or a set of specific questions that are intended to inform a particular domain area (e.g. collaborative learning), online communities, or an analytic method (e.g. ethnographic studies)

## Summary
### Key Points
- It is important to have a good understanding of the problem space, specifying what it is you are doing, why, and how it will support users in the way intended
- A fundamental aspect of interaction design is to develop a conceptual model
- A conceptual model is a high-level description of a product in terms of what users can do with it and the concepts they need in order to understand how to interact with it
- Decisions about conceptual design should be made before commencing physical design (e.g. choosing menus, icons, dialog boxes)
- Interface metaphors are commonly used as part of a conceptual model
- Interaction types (e.g. conversing, instructing) provide a way of thinking about how best to support the activities users will be doing when using a product or service
- Paradigms, visions, theories, models, and frameworks provide different ways of framing and informing design and research

## Examples
### The Star (Xerox, 1981)
The Star interface revolutionized the way interfaces were designed for personal computing. Based on the conceptual model of an office; paper, folders, filing cabinets, mailboxes. 

### Direct Manipulation (Shneiderman, 1983)
Proposes that digital objects be designed at the interface so that they can be interacted with in ways that are analogous to how physical objects in the physical world are manipulated. Users feel that they are directly controlling the digital objects. The benefits of direct manipulation:

- helping beginners learn basic functionality rapidly
- enabling experienced users to work rapidly on a wide range of tasks
- allowing infrequent users to remember how to carry out operations over time
- preventing the need for error messages, except very rarely
- showing users immediately how their actions are furthering their goals
- reducing users' experiences of anxiety
- helping users gain confidence and mastery and feel in control

### Ubiquitous Technology (Weiser, 1991)
He proposed that computers would become part of the environment, embedded in a variety of everyday objects, devices, and displays. The technology would be able to enter our attention when needed and leave when it was finished, constantly running unnoticed in the background

### Apple's 1987 Knowledge Navigator
Presented a scenario of a professor using a touch-screen tablet with a speech-based intelligent assistant reminding him of what he needed to do that day while answering the phone and helping him prepare his lectures. It was 25 years ahead of its time (set in 2011), the actual year that Apple launched its speech system, Siri

### New Challenges, Themes, and Questions (Rogers, 2006, Harper et al, 2008)
Many new challenges, themes, and questions have been articulated through these visions, including:

- How to enable people to access and interact with information in their work, social, and everyday lives, using an assortment of technologies
- How to design user experiences for people using interfaces that are part of the environment but where there are no obvious controlling devices
- How and in what form to provide contextually relevant information to people at appropriate times and places to support them while on the move
- How to ensure that information that is passed around via interconnected displays, devices, and objects is secure and trustworthy

### Relationship between conceptual model and user's understanding (Norman, 1988)
- The designer's model -- the model the designer has of how the system should work
- The system image -- how the system actually works is portrayed to the user through the interface, manuals, help facilities, and so on
- The user's model -- how the user understands how the system works

# Chapter 3 -- Cognitive Aspects
- Explain what cognition is and why it is important for interaction design
- Discuss what attention is and its effects on our ability to multitask
- Describe how memory can be enhanced through technology aids
- Explain what mental models are
- Show the difference between classic internal cognitive frameworks (e.g. mental models) and more recent external cognitive approaches (e.g. distributed cognition) that have been applied to HCI
- Enable you to try to elicit a mental model and be able to understand what it means

## What is Cognition?
There are many different kinds of cognition, such as thinking, remembering, learning, daydreaming, decision making, seeing, reading, writing, and talking. Norman (1993) distinguishes between two general modes: experiential and reflective cognition. Kahneman (2011) describes them in terms of fast and slow thinking. Cognition has also been described in terms of specific kinds of processes:

- attention
- perception
- memory
- learning
- reading, speaking, and listening
- problem solving, planning, reasoning, and decision making

### Attention
Heavy multitaskers are likely to be those who are easily distracted and find it difficult to filter out irrelevant information. 

- Make information salient when it needs attending to at a given stage of a task
- Use techniques like animated graphics, color, underlining, ordering of items, sequencing of different infromation, and spacing of items to achieve this
- Avoid cluttering the interface with too much information. This especially applies to the use of color, sound, and graphics: it is tempting to use lots, resulting in a mishmash of media that is distracting and annoying rather than helping the user attend to relevant information
- Search engines and form fill-ins that have simple and clean interfaces are easier to use

### Perception
Perception refers to how information is acquired from the environment via the different sense of organs - eyes, ears, fingers - and transformed into experiences of objects, events, sounds, and tastes (Roth, 1986). Representations of information need to be designed to be perceptible and recognizable across different media:

- Icons and other graphical representations should enable users to readily distinguish their meaning
- Bordering and spacing are effective visual ways of grouping information that makes it easier to perceive and locate items
- Sounds should be audible and distinguishable so users understand what they represent
- Speech output should enable users to distinguish between the set of spoken words and also be able to understand their meaning
- Text should be legible and distinguishable from the background (e.g. it is okay to use yellow text on a black or blue background but not on a white or green background)
- Tactile feedback used in virtual environments should allow users to recognize the meaning of the various sensations being emulated. The feedback should be distinguishable so that, for example, the sensation of squeezing is represented in a tactile form that is different from the sensation of pushing

### Memory
It seems we remember less about objects when we have photographed them than when we observe them just with the naked eye (Henkel, 2014)

- Do not overload users' memories with complicated procedures for carrying out tasks
- Design interfaces that promote recognition rather than recall by using menus, icons, and consistently placed objects
- Provide users with a variety of ways on encoding digital information (e.g. files, emails, images) to help them access them again easily, through the use of categories, color, tagging, time stamping, icons, etc

### Learning
- Design interfaces that encourages exploration
- Design interfaces that constrain and guide users to select appropriate actions when initially learning
- Dynamically link concrete representations and abstract concepts to facilitate the learning of complex material

### Reading, Speaking, and Listening
Specific differences between the three modes include:

- Written language is permanent while listening is transient. It is possible to re-read information if not understood the first time around. This is not possible with spoken information that is being broadcast
- Reading can be quicker than speaking or listening, as written text can be rapidly scanned in ways not possible while listening to serially presented spoken words
- Listening requires less cognitive effort than reading or speaking. Children, especially, often prefer to listen to narratives provided in multimedia or web-based learning material than to read the equivalent text online
- Written language tends to be grammatical while spoken language is often ungrammatical. For example, people often start talking and stop in mid-sentence, letting someone else start speaking
- Dyslexics have difficulties understanding and recognizing written words, making it hard for them to write grammatical sentences and spell correctly

Many applications have been developed either to capitalize on people's reading, writing, and listening skills, or to support or replace them where they lack or have difficulty with them. These include:

- Interactive books and web-based materials that help people to read or learn foreign languages
- Speech-recognition systems that allow users to interact with them by using spoken commands (e.g. word-processing dictation, Google Voice Search app, and home control devices that respond to vocalized requests)
- Speech-output systems that use artificially generated speech (e.g. written-text-to-speech systems for the blind)
- Natural-language systems that enable users to type in questions and give text-based responses (e.g. the Ask search engine)
- Cognitive aids that help people who find it difficult to read, write, and speak. Numerous special interfaces have been developed for people who have problems with reading, writing, and speaking
- Customized input and output devices that allow people with various disabilities to have access to the web and use word processors and other software packages
- Interaction techniques that allow blind people to read graphs and other visuals on the web through the use of auditory navigation and tactile diagrams (Petrie et al, 2002)

#### Summary
- Keep the length of speech-based menus and instructions to a minimum. Research has shown that people find it hard to follow spoken menus with more than three or four options. Likewise, they are bad at remembering sets of instructions and directions that have more than a few parts
- Accentuate the intonation of artificially generated speech voices, as they are harder to understand than human voices
- Provide opportunities for making text large on a screen, without affecting the formatting, for people who find it hard to read small text

### Problem Solving, Planning, Reasoning, and Decision Making
- Provide additional hidden information that is easy to access for users who wish to understand more about how to carry out an activity more effectively (e.g. web searching)
- Use simple and memorable functions at the interface for computational aids intended to support rapid decision making and planning that takes place while on the move

## Cognitive Frameworks
Internal:

1. Mental Models
1. Gulfs of Execution and Evaluation
    - Execution
        1. Intentions
        1. Action Specification
        1. Interface Mechanism
    - Evaluation
        1. Interface Display
        1. Interpretation
        1. Evaluation
1. Information Processing
    1. Input or Stimuli
    1. Encoding (stage 1)
    1. Comparison (stage 2)
    1. Response Selection (stage 3)
    1. Response Execution (stage 4)
    1. Output or Response

External:

1. Distributed Cognition
    - A distributed cognition analysis typically involves examining:
        - The distributed problem solving that takes place (including the way people work together to solve a problem)
        - The role of verbal and non-verbal behaviour (including what is said, what is implied by glances, winks, and the like, and what is not said)
        - The various coordinating mechanisms that are used (e.g. rules, procedures)
        - The various ways communication takes place as the collaborative activity progresses
        - How knowledge is shared and accessed
1. External Cognition
    - External cognition is concerned with explaining the cognitive processes involved when we interact with different external representations (Scaife and Rogers, 1996). A main goal is to explicate the cognitive benefits of using different representations for different cognitive activities and the processes involved. The main ones include:
        1. Externalizing to reduce memory load
        1. Computational offloading
        1. Annotating and cognitive tracing
            - Annotating involves modifying external representations, such as crossing off or underlining items
            - Cognitive tracing involves externally manipulating items into different orders or structures
1. Embodied Interaction


## Summary
- Cognition comprises many processes, including thinking, attention, learning, memory, perception, decision making, planning, reading, speaking, and listening
- The way an interface is designed can greatly affect how well people can perceive, attend, learn, and remember how to carry out their tasks
- The main benefits of conceptual frameworks and cognitive theories are that they can explain user interaction, inform design, and predict user performance

## Examples
### Seven Plus Or Minus Two (Miller, 1956)
Seven plus or minus two chunks of information can be held in short-term memory at any one time. By short-term memory he meant a memory store in which information was assumed to be processed when first perceived. By chunks he meant a range of items like numbers, letters, or words. According to Miller's theory, therefore people's immediate memory capacity is very limited. They are able to remember only a few words or numbers that they have heard or seen. According to a survey by Bailey (2000), several designers have been led to believe the following guidelines and have even created interfaces based on them:

- Have only seven options on a menu
- Display only seven icons on a menu bar
- Never have more than seven bullets in a list
- Place only seven tabs at the top of a website page
- Place only seven items on a pull-down menu

All of these are wrong

### Relationship Handler (Sas and Wittaker, 2013)
Suggested new ways of harvesting digital materials connected to a broken relationship through using various automatic methods, such as face recognition, that dispose of them without the person needing to personally go through them and be confronted with painful memories. They also suggest that during a separation, people could create a collage of their digital content connected to the ex, so as to transform them into something more abstract, thereby providing a means for closure and helping with the process of moving on

### Cook's Collage (Tran et al, 2005)
Cameras were mounted underneath cabinets to capture still images of a cooking activity. These were then displayed as a series of images, in the form of a cartoon strip, on a flat-panel display mounted on an eye-level kitchen cabinet

### Dynalinking (Rogers and Scaife, 1998)
Abstract representations, such as diagrams, are linked together with a more concrete illustration of what they stand for, such as a simulation. Changes in one are matched by changes in the other, enabling a better understanding of what the abstraction means. An early example of its use was software developed for learning about ecological concepts, such as food webs. A concrete simulation showed various organisms swimming and moving around and occasionally an event where one would eat another

### Human Processor Model (Card et al, 1983)
One of the first HCI models to be derived from the information processing theory. Modelled the cognitive processes of a user interacting with a computer. Cognition was conceptualized as a series of processing stages, where perceptual, cognitive, and motor processors are organized in relation to one another. The model predicts which cognitive processes are involved when a user interacts with a computer, enabling calculations to be made of how long a user will take to carry out various tasks.

# Chapter 4 -- Social Interaction
- Explain what is meant by social interaction
- Describe the social mechanisms that are used by people when communicating and collaborating
- Discuss how social media have changed the ways in which we keep in touch, make contact, and manage our social and working lives
- Explain what is meant by telepresence
- Give an overview of shareable technologies and some of the studies showing how they can facilitate collaboration and group participation

## Face-to-face Conversation
### Rules for conversation (Sacks et al, 1978)
- **Rule 1:** the current speaker chooses the next speaker by asking a question, inviting an opinion, or making a request
- **Rule 2:** another person decides to start speaking
- **Rule 3:** the current speaker continues talking

## Key Points
- Social interaction is central to our everyday life
- Social mechanisms have evolved in face-to-face and remote contexts to facilitate conversation, coordination, and awareness
- Talk and the way it is managed are integral to coordinating social interaction
- Many kinds of computer-mediated communication systems have been developed to enable people to communicate with one another when in physically different locations
- Keeping aware of what others are doing and letting others know what you are doing are important aspects of collaboration and socializing
- Social media has brought about significant changes in the way people keep in touch and manage their social lives

## Examples
### Xerox's Media Space
Allowed people to communicate socially while remaining at their desks

### Cruiser
Cruiser consisted of audio and video equipment on a person's desktop that allowed those connected to 'glance' at who was in their office and whether they wanted to talk or have coffee (Fish, 1989). The idea was to allow people to interact with each other via the video technology in a similar way to how they do when walking down a physical hallway.

### Hydra
Hydra used spatialized audio-video to enhance communication with a group of colleagues -- separate units were place at different places on someone's desk, one assigned to each person connected to the system (Sellen et al, 1992)

### VideoWindow (Bellcore, 1989)
Shared space that allowed people in different locations to carry on a conversation as they would do if drinking coffee together in the same room. Two lounge areas that were 50 miles apart were connected by a 3 foot by 5 foot picture-window onto which video images of each location were projected. The large size enabled viewers to see a room of people roughly the same size as themselves. A study of its use showed that many on the conversations that took place between the remote conversants were indeed indistinguishable from similar face-to-face interactions -- with the exception that they spoke a bit louder and constantly talked about the video system (Kraut et al, 1990)

### Clearboard
Designed to enable facial expressions of participants to be made visible to others by using transparent board that showed their face to the others (Ishii et al, 1993)

### HyperMirror
Synthesized and projected mirror reflections of people in different places onto a single screen, so that they appeared side by side in the same virtual space (Morikawa and Maesako, 1998). Observations of people using the system showed how quickly participants quickly became sensitized to the importance of virtual personal space, moving out of the way if they perceived they were overlapping someone else on the screen

### BiReality
Used a teleoperated robotic surrogate to visit remote locations as a substitute for physical travel (Jouppi et al, 2004). Much attention was paid to its design. An underlying principle was to make it seem like the person was actually there by making the surrogate look and sound like the remote person. Specifically, the robot had a life-size head shaped as a cube, with each side displaying a view of the remote person's face. The head sat on a human-shaped body base that was coloured blue to match the colour of business clothing. Multichannel bidirectional audio was also used to project the remote person's voice. To move in the physical space, the remote person would steer their surrogate using a console from inside their home linked into the remote meeting room. The real people in the meeting room would leave a gap at the table for the surrogate to sit with them

### Reactable Experience (2010)
The Reactable Experience (2010) was designed for groups of children, families, or adults to create music together in public spaces and institutions, such as museums and science centres. Based on the original Reactable (Jorda et al, 2005), colourful tangible pucks are moved and rotated on the surface of a translucent tabletop, which results in various digital annotations appearing and connecting them. A synthesizer creates immediate sounds in response to the various tabletop interactions. One of the main ideas behind the design was to enable groups to create music together on the fly. This is achieved through making visible everyone's interactions at the tabletop surface and by providing real-time feedback about what is currently happening.

### React Table
The table monitors and analyses ongoing conversations using embedded microphones in front of each person and represents this in the form of increasing numbers of coloured LEDs.

### Babble (David Smith)
Provided a dynamic visualization of the participants in an ongoing chat room. A large 2D circle was depicted using coloured marbles on each user's monitor. Marbles inside the circle conveyed those individuals active in the current conversation. Marbles outside the circle showed users involved in other conversations. The more active a participant was in the conversation, the more the corresponding marble moved towards the centre of the circle. Conversely, the less engaged a person was in the ongoing conversation, the more the marble moved towards the periphery of the circle.

### Sococo
Virtual office system, that uses the spatial metaphor of a floor plan of an office to show where people are, who is in a meeting, and who is chatting with whom. It provides a bird's eye view of each floor so that everyone connected can see where everyone is at any given time. It also makes it easy to pop in and say hello to someone -- in the same way office workers might do if they were in the same building.

### Opinionizer
Designed with the aim of encouraging people in an informal gathering to share their opinions visually and anonymously (Brignull ang Rogers, 2003). The collective creation of opinions via a public display was intended to provide a talking point for the people standing beside it. Users submitted their opinions by typing the in at a public keyboard. To add colour and personality to their opinions, a selection of small cartoon avatars and speech bubbles were available. The screen was also divided into four labeled quadrants representing different backgrounds (techie, softie, designer)

### The Dynamo
Enables communities to readily share and exchange a variety of media on a large shared display by hooking up their memory sticks, laptops, cameras, and other devices in the vicinity of the display (lzadi et al, 2003). A study of its deployment in a sixth form common room in the UK showed how students often used it as a conversational prop while displaying and manipulating media on the shared display, which in turn led to impromptu conversations between those sitting in the room (Brignull et al, 2004)

### The Red Nose Game
5 by 5 meter screen, the game starts with red blobs splattered on the screen. The objective of the game is for passers-by to push the blobs together by using their bodies, which are tracked by a live camera feed embedded in the display. When the camera image of a player touches a red nose blob, it enables that person to push it around the screen towards other blobs. The game ends when all the small blobs become one large blob. A study conducted by O'Hara et al (2008) showed that people were reluctant to play in case they made a fool of themselves in front of the other members of the public. If often required a compere to cajole people into playing the game. However once in the game, people worked closely together as groups, developing effective strategies to move their blobs together, such as linking arms and sweeping the blobs together across the screen

### Break-time Barometer
Designed to persuade people to come out of their offices for a break to meet others they might not talk with otherwise (Kirkham et al, 2013). An ambient display, based on a clock metaphor, shows how many people are currently in the common room; if there are people present, it also sends an alert that it would be a good time to join them for a break. While the system nudged some people to go for a break in the staff room, it also had the opposite effect on others who used it to determine when breaks weren't happening so that they could take a break without their colleagues being around for company.

# Chapter 5 -- Emotional Interaction
- Explain how our emotions relate to behaviour and user experience
- Provide examples of interfaces that are both pleasurable and usable
- Explain what expressive and annoying interfaces are and the effects they can have on people
- Introduce that area of automatic emotion recognition and emotional technologies
- Describe how technologies can be designed to change people's attitudes and behaviour
- Give an overview on how anthropomorphism has been applied in interaction design
- Enable you to critique the persuasive impact of an online agent on customers

## Emotions and the User Experience
People express themselves through; facial expressions, body language, gestures, and tone of voice. Baumeister et al (2007) argue that the role of emotion is more complicated than a simple cause and effect model; emotions can be both simple and short-lived or complex and long-lasting.

## Expressive Interfaces
Expressive forms like emoticons, sounds, icons, and virtual agents have been used at the interface to:

1. convey emotional states and/or
1. elicit certain kinds of emotional responses in users, such as feeling at ease, comfort, and happiness

Ways fo conveying the status of a system are through the use of:

- Dynamic icons (e.g. a recycle bin expanding when a file is placed in it and paper disappearing in a puff when emptied)
- Animations (e.g. a beach ball whirling to say the computer is busy)
- Spoken messages, using various kinds of voices, telling the user what needs to be done (e.g. GPS navigation system instructing you politely where to go after having taken a wrong turn)
- Various sonifications indicating actions and events (e.g. whoosh for window closing, schlook for a file being dragged, ding for a new email arriving)
- Vibrotactile feedback, such as distinct smartphone buzzes that specifically represent special messages from friends and family

## Detecting Emotions and Emotional Technology
Six fundamental emotions are classified based on the face expressions; sadness, happiness, disgust, fear, surprise, and anger.

## Anthropomorphism and Zoomorphism
Anthropomorphism is the propensity people have to attribute human qualities to animals and objects while zoomorphism is the shaping of an object or design in animal form. For example, people sometimes talk to their computers as if they were humans, treat their robot cleaners as if they were their pets, and give all manner of cute name to their mobile devices, routers, and so on.

## Summary
- Emotional aspects of interaction design are concerned with how to facilitate certain states (e.g. pleasure) or avoid certain reations (e.g. frustration) in user experiences
- Well-designed interfaces can elicit good feelings in people
- Aesthetically pleasing interfaces can be a pleasure to use
- Expressive interfaces can provide reassuring feedback to users as well as be informative and fun
- Badly designed interfaces often make people frustrated, annoyed, or angry
- Emotional technologies can be designed to persuade people to change their behaviours or attitudes
- Anthropomorphism is the attribution of human qualities to objects
- Virtual agents and robot pets have been developed to make people feel motivated, reassured, and in a good mood

## Examples
### Emotion and Behaviour Model (Ortony et al, 2005)
Couched in terms of different levels of the brain. At the lowest level are parts of the brain that are pre-wired to automatically respond to events happening in the physical world. This is called the visceral level. At the next level are the brain processes that control our everyday behaviour. This is called the behavioural level. At the highest level are brain processes that contemplate. This is called the reflective level. The visceral level responds rapidly, making judgments about what is good or bad, safe or dangerous, pleasurable or abhorrent. It also triggers the emotional responses to stimuli (e.g. fear, joy, anger, and sadness) that are expressed through a combination of physiological and behavioural responses

### Nest
The designs are simple, round, and use bright colors -- this makes them cute and aesthetically pleasing to the eye. The Nest thermostat provides an intelligent way of controlling how your house is heated or cooled.

### Sproutling
The design are simple, round, and use bright colors -- this makes them cute and aesthetically pleasing to the eye. The Sproutling is a band that is wrapped around a baby's ankle that senses heart rate, skin temperature, motion, and position. It communicates with a smartphone app to let parents know if their baby is sleeping soundly or if something is wrong -- using cute baby emoticons

### Moon Phrases
An app that has been developed to help people reflect upon their emotional well-being (do Choudhury et al, 2013). The app allows people to think about their emotional states and feelings via analysing what they say in their postings on Twitter. The aim is to help them cope better with stress and anxiety by recognizing the triggers that cause them to occur. The tool works by analysing the way users express themselves in social media -- through the types of words, mood hashtags, emoticons, and expressions used and their frequency. It then visualizes this data in terms of a series of moon icons conveying positive and negative affect, representing each day for a period of several months; full moons indicate positively, while half or quarter moons reflect more negativity. By looking back at their history of moons, users can start to identify patterns that could help them understand more about themselves and what might be causing their mood swings.

### Nintendo's Pokemon Pikachu
People had a pet pikachu and had to walk to generate steps. Steps resulted in watts that could be used to buy presents for the pikachu. If the pikachu didn't get presents it would get unhappy and refuse to play

### WaterBot
The system was developed using a special monitoring and feedback device, but for adults as a way of reducing their usage of water in their homes (Arroyo et al, 2005). There is much evidence to suggest that people are wasteful with water, often leaving the tap running continuously for long periods of time while cleaning their teeth or washing. The research team thought that the use of monitoring technology could help persuade householders to change their behaviour to be more conservative in their water usage. To this end, they used the theory of positive reinforcement to inform their design, which states that activities are likely to be repeated if some kind of reward is given occasionally and randomly (similar to the reward system used in slot machines). A sensor-based system was developed where positive auditory messages and chimes were sounded when the tap was turned off. The water was also lit with a random pattern of colour as a reward for consistent water-saving behaviour. Two illuminated bar graphs were also presented alongside the tap, showing how much water a person had used relative to others in the household. Here, the idea was to encourage peer pressure and for the members of the household to talk to each other about their water usage. Informal feedback of the prototype system in a small number of people's homes suggested that the most effective method of persuassion was the constantly changing bar graph. It drew people's attention to the tap, leading them to make quick comparisons between their and the others' water consumption. The rewards of chimes and coloured water had less impact, especially as their novelty wore off.

### HAPIfork
It is intended to help someone monitor and track their eating habits. If it detects they are eating too quickly, it will vibrate (similar to the way asmartphone does when on silent mode) and an ambient light will appear at the end of the fork, providing the eater with real-time feedback intended to slow them down. The assumption is that eating too fast results in poor digestion and poor weight control, and that making people aware that they are gobbling their food down can help them think about how to eat more slowly at a conscious level. Other data is collected about how long it took them to finish their meal, the amount of fork servings per minute, and the time between them. These are turned into a dashboard of graphs and statistics so the user can see each week whether their fork behaviour is improving.
